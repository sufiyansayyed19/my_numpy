{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Working with Text Files\n",
                "\n",
                "**Module 06 | Notebook 02**\n",
                "\n",
                "---\n",
                "\n",
                "## Objective\n",
                "By the end of this notebook, you will master:\n",
                "- Reading text/CSV files with np.loadtxt\n",
                "- Reading with np.genfromtxt for missing data\n",
                "- Writing arrays to text files\n",
                "- Handling different delimiters and formats\n",
                "- Performance considerations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import os\n",
                "np.set_printoptions(precision=2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. np.savetxt() - Writing Text Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save array to text file\n",
                "arr = np.arange(12).reshape(3, 4)\n",
                "print(f\"Array to save:\\n{arr}\")\n",
                "\n",
                "np.savetxt('array.txt', arr)\n",
                "print(\"\\nSaved to array.txt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the file contents\n",
                "with open('array.txt', 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom delimiter (CSV)\n",
                "np.savetxt('array.csv', arr, delimiter=',')\n",
                "\n",
                "with open('array.csv', 'r') as f:\n",
                "    print(\"CSV format:\")\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom format and header\n",
                "np.savetxt('formatted.csv', arr, \n",
                "           delimiter=',',\n",
                "           fmt='%d',           # Integer format\n",
                "           header='Col1,Col2,Col3,Col4',\n",
                "           comments='')        # No # before header\n",
                "\n",
                "with open('formatted.csv', 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Format specifiers\n",
                "floats = np.random.rand(3, 4) * 100\n",
                "\n",
                "# Different formats\n",
                "np.savetxt('fmt_default.txt', floats)           # Default scientific\n",
                "np.savetxt('fmt_fixed.txt', floats, fmt='%.2f') # 2 decimal places\n",
                "np.savetxt('fmt_int.txt', floats, fmt='%d')     # Integer\n",
                "\n",
                "print(\"Fixed point format:\")\n",
                "with open('fmt_fixed.txt', 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. np.loadtxt() - Reading Text Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic loading\n",
                "loaded = np.loadtxt('array.txt')\n",
                "print(f\"Loaded from txt:\\n{loaded}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CSV\n",
                "loaded_csv = np.loadtxt('array.csv', delimiter=',')\n",
                "print(f\"Loaded from CSV:\\n{loaded_csv}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load with header skip\n",
                "loaded_header = np.loadtxt('formatted.csv', delimiter=',', skiprows=1)\n",
                "print(f\"Skipped header:\\n{loaded_header}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load specific columns\n",
                "np.savetxt('multicol.csv', np.arange(20).reshape(4, 5), delimiter=',')\n",
                "\n",
                "# Load only columns 0 and 2\n",
                "selected = np.loadtxt('multicol.csv', delimiter=',', usecols=(0, 2, 4))\n",
                "print(f\"Selected columns:\\n{selected}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify dtype\n",
                "loaded_int = np.loadtxt('array.csv', delimiter=',', dtype=int)\n",
                "print(f\"As integers:\\n{loaded_int}\")\n",
                "print(f\"Dtype: {loaded_int.dtype}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Unpack to separate arrays\n",
                "col1, col2, col3, col4 = np.loadtxt('array.csv', delimiter=',', unpack=True)\n",
                "print(f\"Column 1: {col1}\")\n",
                "print(f\"Column 2: {col2}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. np.genfromtxt() - Handling Missing Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create file with missing values\n",
                "with open('missing.csv', 'w') as f:\n",
                "    f.write(\"1,2,3\\n\")\n",
                "    f.write(\"4,,6\\n\")      # Missing value\n",
                "    f.write(\"7,8,\\n\")      # Missing at end\n",
                "    f.write(\",10,11\\n\")    # Missing at start\n",
                "\n",
                "print(\"File with missing values:\")\n",
                "with open('missing.csv', 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# loadtxt would fail on missing data\n",
                "# genfromtxt handles it\n",
                "data = np.genfromtxt('missing.csv', delimiter=',')\n",
                "print(f\"With genfromtxt (NaN for missing):\\n{data}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify fill value for missing\n",
                "data = np.genfromtxt('missing.csv', delimiter=',', filling_values=0)\n",
                "print(f\"Fill with 0:\\n{data}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create file with header and mixed types\n",
                "with open('mixed.csv', 'w') as f:\n",
                "    f.write(\"name,age,score\\n\")\n",
                "    f.write(\"Alice,25,95.5\\n\")\n",
                "    f.write(\"Bob,30,87.0\\n\")\n",
                "    f.write(\"Charlie,35,92.5\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load with automatic dtype detection\n",
                "data = np.genfromtxt('mixed.csv', delimiter=',', \n",
                "                      names=True,      # First row is header\n",
                "                      dtype=None,      # Auto-detect types\n",
                "                      encoding='utf-8')\n",
                "\n",
                "print(f\"Structured array:\\n{data}\")\n",
                "print(f\"Names: {data['name']}\")\n",
                "print(f\"Ages: {data['age']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom converters\n",
                "with open('dates.csv', 'w') as f:\n",
                "    f.write(\"2023-01-15,100\\n\")\n",
                "    f.write(\"2023-02-20,200\\n\")\n",
                "\n",
                "# Convert date string to days since 2023-01-01\n",
                "def date_converter(s):\n",
                "    parts = s.split(b'-')\n",
                "    return int(parts[1]) * 30 + int(parts[2])\n",
                "\n",
                "data = np.genfromtxt('dates.csv', delimiter=',',\n",
                "                      converters={0: date_converter})\n",
                "print(f\"With date conversion:\\n{data}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Other Text Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# np.fromstring - parse string to array\n",
                "s = \"1 2 3 4 5\"\n",
                "arr = np.fromstring(s, dtype=int, sep=' ')\n",
                "print(f\"From string: {arr}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# np.array2string - format array as string\n",
                "arr = np.array([[1.23456, 2.34567], [3.45678, 4.56789]])\n",
                "s = np.array2string(arr, precision=2, separator=', ')\n",
                "print(f\"Array as string:\\n{s}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# np.set_string_function - customize repr (advanced)\n",
                "# np.fromregex - parse using regex (advanced)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Performance: loadtxt vs genfromtxt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create larger test file\n",
                "large = np.random.rand(10000, 10)\n",
                "np.savetxt('large.csv', large, delimiter=',')\n",
                "\n",
                "import time\n",
                "\n",
                "# loadtxt\n",
                "start = time.time()\n",
                "data1 = np.loadtxt('large.csv', delimiter=',')\n",
                "loadtxt_time = time.time() - start\n",
                "\n",
                "# genfromtxt\n",
                "start = time.time()\n",
                "data2 = np.genfromtxt('large.csv', delimiter=',')\n",
                "genfromtxt_time = time.time() - start\n",
                "\n",
                "print(f\"loadtxt: {loadtxt_time:.3f}s\")\n",
                "print(f\"genfromtxt: {genfromtxt_time:.3f}s\")\n",
                "print(f\"loadtxt is ~{genfromtxt_time/loadtxt_time:.1f}x faster\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For very large files, consider pandas\n",
                "# pandas.read_csv is highly optimized\n",
                "# Can convert to numpy: df.values or df.to_numpy()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Common Patterns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pattern: Load numeric data, skip text header\n",
                "with open('data_with_header.csv', 'w') as f:\n",
                "    f.write(\"# This is a comment\\n\")\n",
                "    f.write(\"# Another comment\\n\")\n",
                "    f.write(\"x,y,z\\n\")\n",
                "    f.write(\"1,2,3\\n\")\n",
                "    f.write(\"4,5,6\\n\")\n",
                "\n",
                "data = np.loadtxt('data_with_header.csv', delimiter=',', \n",
                "                   skiprows=3,    # Skip first 3 lines\n",
                "                   comments='#')  # Ignore lines starting with #\n",
                "print(f\"Data:\\n{data}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pattern: Read subset of large file\n",
                "# First 100 rows\n",
                "subset = np.loadtxt('large.csv', delimiter=',', max_rows=100)\n",
                "print(f\"Subset shape: {subset.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pattern: Write with row names\n",
                "data = np.random.rand(3, 4)\n",
                "row_names = ['Row1', 'Row2', 'Row3']\n",
                "\n",
                "with open('with_rownames.csv', 'w') as f:\n",
                "    f.write(',Col1,Col2,Col3,Col4\\n')\n",
                "    for name, row in zip(row_names, data):\n",
                "        f.write(f\"{name},{','.join(f'{x:.3f}' for x in row)}\\n\")\n",
                "\n",
                "with open('with_rownames.csv', 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Key Points Summary\n",
                "\n",
                "**Writing:**\n",
                "- `np.savetxt()`: Arrays to text files\n",
                "- `fmt` for format, `delimiter` for separator\n",
                "- `header` and `comments` for metadata\n",
                "\n",
                "**Reading:**\n",
                "- `np.loadtxt()`: Simple, fast, strict\n",
                "- `np.genfromtxt()`: Flexible, handles missing data\n",
                "- Key params: `delimiter`, `skiprows`, `usecols`, `dtype`\n",
                "\n",
                "**Best Practices:**\n",
                "- Use loadtxt for clean data (faster)\n",
                "- Use genfromtxt for messy/missing data\n",
                "- Consider pandas for very large CSV files"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Interview Tips\n",
                "\n",
                "**Q1: Difference between loadtxt and genfromtxt?**\n",
                "> - loadtxt: Faster, but requires clean data with no missing values\n",
                "> - genfromtxt: Handles missing data, auto-detect dtypes, more flexible\n",
                "\n",
                "**Q2: How do you handle CSV with header row?**\n",
                "> `np.loadtxt(..., skiprows=1)` or `np.genfromtxt(..., names=True)`\n",
                "\n",
                "**Q3: How to read only specific columns?**\n",
                "> Use `usecols=(0, 2, 4)` parameter with column indices\n",
                "\n",
                "**Q4: Best approach for large CSV files?**\n",
                "> Use pandas.read_csv (optimized), then convert to numpy with `.to_numpy()`. For very large files, use chunked reading."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean up test files\n",
                "import glob\n",
                "\n",
                "for f in glob.glob('*.txt') + glob.glob('*.csv'):\n",
                "    os.remove(f)\n",
                "    print(f\"Removed: {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Next Notebook\n",
                "**03_binary_and_compressed_files.ipynb** - Working with binary formats and other file types."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}