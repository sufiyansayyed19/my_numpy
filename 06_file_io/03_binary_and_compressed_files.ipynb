{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Binary and Compressed Files\n",
                "\n",
                "**Module 06 | Notebook 03**\n",
                "\n",
                "---\n",
                "\n",
                "## Objective\n",
                "By the end of this notebook, you will master:\n",
                "- Working with raw binary files\n",
                "- np.fromfile and np.tofile\n",
                "- Interfacing with other formats (HDF5, etc.)\n",
                "- Buffer protocol and bytes\n",
                "- Data exchange with other languages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import os\n",
                "np.set_printoptions(precision=2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. np.tofile() and np.fromfile() - Raw Binary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write array to raw binary file\n",
                "arr = np.arange(12, dtype=np.float64).reshape(3, 4)\n",
                "print(f\"Array to save:\\n{arr}\")\n",
                "print(f\"Dtype: {arr.dtype}, Shape: {arr.shape}\")\n",
                "\n",
                "arr.tofile('raw_array.bin')\n",
                "print(f\"\\nFile size: {os.path.getsize('raw_array.bin')} bytes\")\n",
                "print(f\"Expected: {arr.nbytes} bytes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read raw binary - MUST know dtype!\n",
                "loaded = np.fromfile('raw_array.bin', dtype=np.float64)\n",
                "print(f\"Loaded (flat): {loaded}\")\n",
                "\n",
                "# Shape is lost! Must reshape manually\n",
                "loaded = loaded.reshape(3, 4)\n",
                "print(f\"Reshaped:\\n{loaded}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Wrong dtype gives garbage\n",
                "wrong = np.fromfile('raw_array.bin', dtype=np.int32)\n",
                "print(f\"Wrong dtype (int32):\\n{wrong[:8]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read subset with count and offset\n",
                "# Read 4 elements starting from element 2\n",
                "subset = np.fromfile('raw_array.bin', dtype=np.float64, \n",
                "                      count=4, offset=16)  # 16 = 2 * 8 bytes\n",
                "print(f\"Subset: {subset}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# tofile with separator (text mode)\n",
                "arr = np.arange(5)\n",
                "arr.tofile('text_binary.txt', sep=',')\n",
                "\n",
                "with open('text_binary.txt', 'r') as f:\n",
                "    print(f\"Text format: {f.read()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. np.frombuffer() - From Bytes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create array from bytes object\n",
                "arr = np.arange(5, dtype=np.int32)\n",
                "raw_bytes = arr.tobytes()\n",
                "\n",
                "print(f\"Original array: {arr}\")\n",
                "print(f\"As bytes: {raw_bytes}\")\n",
                "print(f\"Bytes length: {len(raw_bytes)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reconstruct from bytes\n",
                "recovered = np.frombuffer(raw_bytes, dtype=np.int32)\n",
                "print(f\"Recovered: {recovered}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# frombuffer creates view (if possible)\n",
                "ba = bytearray(raw_bytes)\n",
                "view = np.frombuffer(ba, dtype=np.int32)\n",
                "\n",
                "# Modify bytearray\n",
                "ba[0:4] = b'\\xff\\xff\\xff\\xff'\n",
                "print(f\"Modified via bytearray: {view}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Useful for network data, shared memory, etc.\n",
                "# Example: parse binary protocol header\n",
                "header_bytes = b'\\x01\\x00\\x00\\x00\\x0a\\x00\\x00\\x00'  # version=1, length=10\n",
                "header = np.frombuffer(header_bytes, dtype=np.uint32)\n",
                "print(f\"Version: {header[0]}, Length: {header[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Byte Order (Endianness)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check system byte order\n",
                "import sys\n",
                "print(f\"System byte order: {sys.byteorder}\")\n",
                "\n",
                "# Little-endian: least significant byte first (x86, ARM)\n",
                "# Big-endian: most significant byte first (network protocols)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify byte order in dtype\n",
                "arr_native = np.array([1, 256, 65536], dtype='<i4')  # Little-endian\n",
                "arr_big = np.array([1, 256, 65536], dtype='>i4')     # Big-endian\n",
                "\n",
                "print(f\"Native bytes: {arr_native.tobytes().hex()}\")\n",
                "print(f\"Big-endian bytes: {arr_big.tobytes().hex()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Swap byte order\n",
                "arr = np.array([1, 256], dtype=np.int32)\n",
                "print(f\"Original: {arr}\")\n",
                "\n",
                "swapped = arr.byteswap()\n",
                "print(f\"Byte-swapped: {swapped}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# newbyteorder: change interpretation without swapping\n",
                "arr = np.array([1], dtype='<i4')\n",
                "print(f\"Original dtype: {arr.dtype}\")\n",
                "\n",
                "reinterpreted = arr.view(arr.dtype.newbyteorder('>'))\n",
                "print(f\"Reinterpreted dtype: {reinterpreted.dtype}\")\n",
                "print(f\"Reinterpreted value: {reinterpreted}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Working with Other Formats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# HDF5 (requires h5py)\n",
                "# pip install h5py\n",
                "\n",
                "try:\n",
                "    import h5py\n",
                "    \n",
                "    # Create HDF5 file\n",
                "    with h5py.File('data.h5', 'w') as f:\n",
                "        f.create_dataset('dataset1', data=np.random.rand(100, 100))\n",
                "        f.create_dataset('dataset2', data=np.arange(1000))\n",
                "        f['dataset1'].attrs['description'] = 'Random matrix'\n",
                "    \n",
                "    # Read HDF5 file\n",
                "    with h5py.File('data.h5', 'r') as f:\n",
                "        print(f\"Datasets: {list(f.keys())}\")\n",
                "        data = f['dataset1'][:]\n",
                "        print(f\"dataset1 shape: {data.shape}\")\n",
                "        \n",
                "    os.remove('data.h5')\n",
                "    print(\"HDF5 example complete\")\n",
                "except ImportError:\n",
                "    print(\"h5py not installed. Skip HDF5 example.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# MATLAB .mat files (requires scipy)\n",
                "try:\n",
                "    from scipy import io as sio\n",
                "    \n",
                "    # Save as .mat\n",
                "    data = {'arr1': np.random.rand(10, 10), 'arr2': np.arange(100)}\n",
                "    sio.savemat('data.mat', data)\n",
                "    \n",
                "    # Load .mat\n",
                "    loaded = sio.loadmat('data.mat')\n",
                "    print(f\"Keys: {[k for k in loaded.keys() if not k.startswith('__')]}\")\n",
                "    print(f\"arr1 shape: {loaded['arr1'].shape}\")\n",
                "    \n",
                "    os.remove('data.mat')\n",
                "    print(\"MATLAB example complete\")\n",
                "except ImportError:\n",
                "    print(\"scipy not installed. Skip MATLAB example.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Image files (PIL/Pillow)\n",
                "try:\n",
                "    from PIL import Image\n",
                "    \n",
                "    # Create image from array\n",
                "    img_array = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)\n",
                "    img = Image.fromarray(img_array)\n",
                "    img.save('test_image.png')\n",
                "    \n",
                "    # Load image to array\n",
                "    loaded_img = Image.open('test_image.png')\n",
                "    loaded_array = np.array(loaded_img)\n",
                "    \n",
                "    print(f\"Image shape: {loaded_array.shape}\")\n",
                "    print(f\"Dtype: {loaded_array.dtype}\")\n",
                "    \n",
                "    os.remove('test_image.png')\n",
                "    print(\"Image example complete\")\n",
                "except ImportError:\n",
                "    print(\"Pillow not installed. Skip image example.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Structured Binary Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read structured binary (e.g., from C program)\n",
                "# struct { int32 id; float32 value; char name[10]; }\n",
                "\n",
                "dt = np.dtype([('id', 'i4'), ('value', 'f4'), ('name', 'S10')])\n",
                "print(f\"Record size: {dt.itemsize} bytes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create and save\n",
                "records = np.array([\n",
                "    (1, 3.14, b'Alice'),\n",
                "    (2, 2.71, b'Bob'),\n",
                "    (3, 1.41, b'Charlie')\n",
                "], dtype=dt)\n",
                "\n",
                "records.tofile('records.bin')\n",
                "print(f\"Saved {len(records)} records\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read back\n",
                "loaded = np.fromfile('records.bin', dtype=dt)\n",
                "print(f\"Loaded records:\\n{loaded}\")\n",
                "print(f\"\\nIDs: {loaded['id']}\")\n",
                "print(f\"Values: {loaded['value']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pattern: Save metadata header + data\n",
                "def save_with_header(filename, arr):\n",
                "    \"\"\"Save array with shape/dtype header.\"\"\"\n",
                "    with open(filename, 'wb') as f:\n",
                "        # Write header: ndim, shape, dtype string\n",
                "        header = f\"{arr.ndim},{','.join(map(str, arr.shape))},{arr.dtype}\\n\"\n",
                "        f.write(header.encode())\n",
                "        # Write data\n",
                "        f.write(arr.tobytes())\n",
                "\n",
                "def load_with_header(filename):\n",
                "    \"\"\"Load array with shape/dtype header.\"\"\"\n",
                "    with open(filename, 'rb') as f:\n",
                "        # Read header\n",
                "        header = f.readline().decode().strip()\n",
                "        parts = header.split(',')\n",
                "        ndim = int(parts[0])\n",
                "        shape = tuple(map(int, parts[1:1+ndim]))\n",
                "        dtype = parts[-1]\n",
                "        # Read data\n",
                "        data = np.frombuffer(f.read(), dtype=dtype)\n",
                "        return data.reshape(shape)\n",
                "\n",
                "# Test\n",
                "arr = np.random.rand(3, 4)\n",
                "save_with_header('custom.bin', arr)\n",
                "loaded = load_with_header('custom.bin')\n",
                "print(f\"Original shape: {arr.shape}\")\n",
                "print(f\"Loaded shape: {loaded.shape}\")\n",
                "print(f\"Match: {np.allclose(arr, loaded)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Data Exchange with C/Fortran"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure contiguous memory for C interop\n",
                "arr = np.random.rand(3, 4)\n",
                "transposed = arr.T  # Not C-contiguous!\n",
                "\n",
                "print(f\"Original C-contiguous: {arr.flags['C_CONTIGUOUS']}\")\n",
                "print(f\"Transposed C-contiguous: {transposed.flags['C_CONTIGUOUS']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make contiguous copy\n",
                "c_contiguous = np.ascontiguousarray(transposed)\n",
                "f_contiguous = np.asfortranarray(transposed)\n",
                "\n",
                "print(f\"C-contiguous: {c_contiguous.flags['C_CONTIGUOUS']}\")\n",
                "print(f\"F-contiguous: {f_contiguous.flags['F_CONTIGUOUS']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get raw pointer for C extension\n",
                "arr = np.arange(10, dtype=np.float64)\n",
                "\n",
                "# ctypes interface\n",
                "ptr = arr.ctypes.data\n",
                "print(f\"Data pointer: {ptr}\")\n",
                "print(f\"Shape pointer: {arr.ctypes.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Key Points Summary\n",
                "\n",
                "**Raw Binary:**\n",
                "- `arr.tofile()`: Write raw bytes\n",
                "- `np.fromfile()`: Read raw bytes (need dtype!)\n",
                "- Shape and dtype are NOT saved\n",
                "\n",
                "**Bytes/Buffer:**\n",
                "- `arr.tobytes()`: Array to bytes\n",
                "- `np.frombuffer()`: Bytes to array\n",
                "- Useful for network/shared memory\n",
                "\n",
                "**Other Formats:**\n",
                "- HDF5: h5py library\n",
                "- MATLAB: scipy.io\n",
                "- Images: PIL/Pillow\n",
                "\n",
                "**C Interop:**\n",
                "- Ensure contiguous memory\n",
                "- Use ctypes for raw pointers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Interview Tips\n",
                "\n",
                "**Q1: Difference between tofile and save?**\n",
                "> - `tofile()`: Raw binary, no metadata (dtype/shape lost)\n",
                "> - `save()`: NumPy format with full metadata\n",
                "> Use `save` for Python-only; `tofile` for C interop\n",
                "\n",
                "**Q2: What is byte order and why does it matter?**\n",
                "> Byte order (endianness) is how multi-byte values are stored. Little-endian stores LSB first; big-endian stores MSB first. Matters when exchanging binary data between systems.\n",
                "\n",
                "**Q3: How do you read binary data from a C struct?**\n",
                "> Define matching structured dtype, then use `np.fromfile()` or `np.frombuffer()`. Ensure byte order and alignment match.\n",
                "\n",
                "**Q4: How to ensure array is contiguous for C functions?**\n",
                "> Use `np.ascontiguousarray()` for C or `np.asfortranarray()` for Fortran. Check with `arr.flags['C_CONTIGUOUS']`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean up test files\n",
                "import glob\n",
                "\n",
                "for f in glob.glob('*.bin') + glob.glob('*.txt'):\n",
                "    os.remove(f)\n",
                "    print(f\"Removed: {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Module 06 Complete!\n",
                "\n",
                "You have mastered File I/O:\n",
                "- Saving and Loading Arrays\n",
                "- Working with Text Files\n",
                "- Binary and Compressed Files\n",
                "\n",
                "**Next Module:** 07_performance_optimization - Memory layout, vectorization best practices, and profiling!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}