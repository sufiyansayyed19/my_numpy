{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Memory Layout and Views\n",
                "\n",
                "**Module 07 | Notebook 01**\n",
                "\n",
                "---\n",
                "\n",
                "## Objective\n",
                "By the end of this notebook, you will master:\n",
                "- Understanding memory layout (C vs F order)\n",
                "- Strides and contiguous arrays\n",
                "- Views vs copies for performance\n",
                "- Cache-friendly access patterns\n",
                "- Memory alignment and efficiency"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import time\n",
                "np.set_printoptions(precision=2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. C-Order vs Fortran-Order"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# C-order (row-major): last index changes fastest\n",
                "# Fortran-order (column-major): first index changes fastest\n",
                "\n",
                "arr_c = np.arange(12).reshape(3, 4, order='C')\n",
                "arr_f = np.arange(12).reshape(3, 4, order='F')\n",
                "\n",
                "print(\"C-order (row-major):\")\n",
                "print(arr_c)\n",
                "print(f\"Memory layout: {arr_c.flatten('K')}\")\n",
                "\n",
                "print(\"\\nFortran-order (column-major):\")\n",
                "print(arr_f)\n",
                "print(f\"Memory layout: {arr_f.flatten('K')}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check order with flags\n",
                "print(f\"C-order: C={arr_c.flags['C_CONTIGUOUS']}, F={arr_c.flags['F_CONTIGUOUS']}\")\n",
                "print(f\"F-order: C={arr_f.flags['C_CONTIGUOUS']}, F={arr_f.flags['F_CONTIGUOUS']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Strides reveal memory layout\n",
                "print(f\"C-order strides: {arr_c.strides}\")\n",
                "print(f\"F-order strides: {arr_f.strides}\")\n",
                "\n",
                "# C: (16, 4) = jump 16 bytes for row, 4 bytes for column (int32)\n",
                "# F: (4, 12) = jump 4 bytes for row, 12 bytes for column"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Performance: iterate in memory order!\n",
                "n = 2000\n",
                "arr_c = np.random.rand(n, n)\n",
                "arr_f = np.asfortranarray(arr_c)\n",
                "\n",
                "# Row-wise sum (good for C-order)\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    _ = arr_c.sum(axis=1)\n",
                "c_row_time = time.perf_counter() - start\n",
                "\n",
                "# Column-wise sum (good for F-order)  \n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    _ = arr_f.sum(axis=0)\n",
                "f_col_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"C-order row sum: {c_row_time*100:.1f}ms\")\n",
                "print(f\"F-order col sum: {f_col_time*100:.1f}ms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Understanding Strides"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.arange(24).reshape(2, 3, 4)\n",
                "print(f\"Shape: {arr.shape}\")\n",
                "print(f\"Strides: {arr.strides}\")\n",
                "print(f\"Item size: {arr.itemsize} bytes\")\n",
                "\n",
                "# Strides: (48, 16, 4)\n",
                "# - Move to next [0] -> 48 bytes = 12 elements * 4 bytes\n",
                "# - Move to next [1] -> 16 bytes = 4 elements * 4 bytes  \n",
                "# - Move to next [2] -> 4 bytes = 1 element * 4 bytes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Slicing changes strides but not data layout\n",
                "arr = np.arange(20).reshape(4, 5)\n",
                "print(f\"Original strides: {arr.strides}\")\n",
                "\n",
                "# Every other row\n",
                "sliced = arr[::2]\n",
                "print(f\"Every 2nd row strides: {sliced.strides}\")\n",
                "\n",
                "# Every other column\n",
                "sliced2 = arr[:, ::2]\n",
                "print(f\"Every 2nd col strides: {sliced2.strides}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Transpose: just swaps strides!\n",
                "arr = np.arange(12).reshape(3, 4)\n",
                "print(f\"Original: shape={arr.shape}, strides={arr.strides}\")\n",
                "\n",
                "trans = arr.T\n",
                "print(f\"Transposed: shape={trans.shape}, strides={trans.strides}\")\n",
                "print(f\"Same memory: {np.shares_memory(arr, trans)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Non-contiguous array (after transpose)\n",
                "print(f\"Original contiguous: {arr.flags['C_CONTIGUOUS']}\")\n",
                "print(f\"Transposed contiguous: {trans.flags['C_CONTIGUOUS']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Views vs Copies Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Views are essentially free (just metadata)\n",
                "arr = np.random.rand(10000, 10000)\n",
                "\n",
                "# View operations\n",
                "start = time.perf_counter()\n",
                "for _ in range(1000):\n",
                "    view = arr[::2, ::2]  # View\n",
                "view_time = time.perf_counter() - start\n",
                "\n",
                "# Copy operations\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    copy = arr[::2, ::2].copy()  # Copy\n",
                "copy_time = (time.perf_counter() - start) * 100  # Scale for comparison\n",
                "\n",
                "print(f\"1000 views: {view_time*1000:.2f}ms\")\n",
                "print(f\"1000 copies (estimated): {copy_time*1000:.2f}ms\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# When to make explicit copy:\n",
                "# 1. Need independent data\n",
                "# 2. Want contiguous memory for better performance\n",
                "# 3. Prevent memory leak (small view of huge array)\n",
                "\n",
                "# Example: Memory leak prevention\n",
                "huge_arr = np.random.rand(10000, 10000)\n",
                "small_view = huge_arr[0:10, 0:10]  # Still references huge_arr!\n",
                "\n",
                "# To free huge_arr, make copy\n",
                "small_copy = huge_arr[0:10, 0:10].copy()\n",
                "del huge_arr  # Now huge_arr memory can be freed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Cache-Friendly Access"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cache lines: CPU loads data in chunks (typically 64 bytes)\n",
                "# Sequential access = good cache utilization\n",
                "# Random access = cache misses\n",
                "\n",
                "n = 5000\n",
                "arr = np.random.rand(n, n)\n",
                "\n",
                "# Row-wise iteration (cache-friendly for C-order)\n",
                "start = time.perf_counter()\n",
                "total = 0\n",
                "for i in range(n):\n",
                "    total += arr[i, :].sum()\n",
                "row_time = time.perf_counter() - start\n",
                "\n",
                "# Column-wise iteration (cache-unfriendly for C-order)\n",
                "start = time.perf_counter()\n",
                "total = 0\n",
                "for j in range(n):\n",
                "    total += arr[:, j].sum()\n",
                "col_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Row-wise (cache-friendly): {row_time:.3f}s\")\n",
                "print(f\"Column-wise (cache-unfriendly): {col_time:.3f}s\")\n",
                "print(f\"Ratio: {col_time/row_time:.1f}x slower\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Better: use vectorized operations (NumPy handles cache)\n",
                "start = time.perf_counter()\n",
                "total = arr.sum(axis=1).sum()  # Row sums\n",
                "vec_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Vectorized: {vec_time:.5f}s\")\n",
                "print(f\"Speedup vs loop: {row_time/vec_time:.0f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Memory Alignment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# NumPy aligns arrays for SIMD operations\n",
                "arr = np.random.rand(1000)\n",
                "\n",
                "# Check alignment (data pointer address)\n",
                "print(f\"Data pointer: {arr.ctypes.data}\")\n",
                "print(f\"Aligned to 64 bytes: {arr.ctypes.data % 64 == 0}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Slicing can break alignment\n",
                "arr = np.arange(100, dtype=np.float64)\n",
                "print(f\"Original aligned: {arr.ctypes.data % 64 == 0}\")\n",
                "\n",
                "sliced = arr[1:]  # Offset by 8 bytes\n",
                "print(f\"Sliced[1:] aligned: {sliced.ctypes.data % 64 == 0}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Flags tell you about alignment\n",
                "arr = np.random.rand(100)\n",
                "print(f\"ALIGNED: {arr.flags['ALIGNED']}\")\n",
                "print(f\"WRITEABLE: {arr.flags['WRITEABLE']}\")\n",
                "print(f\"C_CONTIGUOUS: {arr.flags['C_CONTIGUOUS']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Making Arrays Contiguous"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.arange(12).reshape(3, 4)\n",
                "trans = arr.T  # Non-contiguous\n",
                "\n",
                "print(f\"Transpose contiguous: {trans.flags['C_CONTIGUOUS']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make contiguous\n",
                "contiguous = np.ascontiguousarray(trans)\n",
                "print(f\"After ascontiguousarray: {contiguous.flags['C_CONTIGUOUS']}\")\n",
                "print(f\"Made copy: {not np.shares_memory(trans, contiguous)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Performance impact\n",
                "n = 3000\n",
                "arr = np.random.rand(n, n)\n",
                "trans = arr.T  # Non-contiguous\n",
                "contig = np.ascontiguousarray(trans)\n",
                "\n",
                "# Operation on non-contiguous\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    _ = trans.sum(axis=1)\n",
                "non_contig_time = time.perf_counter() - start\n",
                "\n",
                "# Operation on contiguous\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    _ = contig.sum(axis=1)\n",
                "contig_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Non-contiguous: {non_contig_time*1000:.1f}ms\")\n",
                "print(f\"Contiguous: {contig_time*1000:.1f}ms\")\n",
                "print(f\"Speedup: {non_contig_time/contig_time:.2f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. In-Place Operations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# In-place operations avoid allocation\n",
                "arr = np.random.rand(10000000)\n",
                "\n",
                "# Not in-place (allocates new array)\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    result = arr * 2\n",
                "alloc_time = time.perf_counter() - start\n",
                "\n",
                "# In-place\n",
                "arr = np.random.rand(10000000)\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    arr *= 2\n",
                "    arr /= 2  # Undo for fair comparison\n",
                "inplace_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Allocating: {alloc_time:.3f}s\")\n",
                "print(f\"In-place: {inplace_time:.3f}s\")\n",
                "print(f\"Speedup: {alloc_time/inplace_time:.2f}x\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using 'out' parameter\n",
                "a = np.random.rand(1000000)\n",
                "b = np.random.rand(1000000)\n",
                "result = np.empty_like(a)\n",
                "\n",
                "# Pre-allocated output\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    np.add(a, b, out=result)\n",
                "out_time = time.perf_counter() - start\n",
                "\n",
                "# Normal (allocates each time)\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    result = a + b\n",
                "normal_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"With out: {out_time:.4f}s\")\n",
                "print(f\"Normal: {normal_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Key Points Summary\n",
                "\n",
                "**Memory Order:**\n",
                "- C-order (row-major): NumPy default\n",
                "- F-order (column-major): Use for Fortran interop\n",
                "- Iterate along contiguous dimension for speed\n",
                "\n",
                "**Strides:**\n",
                "- Define bytes to jump per dimension\n",
                "- Views just change strides (no copy)\n",
                "- Non-contiguous = performance hit\n",
                "\n",
                "**Best Practices:**\n",
                "- Use views when possible\n",
                "- Make contiguous before heavy computation\n",
                "- Use in-place operations / `out` parameter\n",
                "- Iterate in memory order"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Interview Tips\n",
                "\n",
                "**Q1: What's the difference between C and Fortran order?**\n",
                "> C-order stores rows contiguously (last index varies fastest). Fortran-order stores columns contiguously (first index varies fastest). Default is C.\n",
                "\n",
                "**Q2: Why is iterating over columns slow in C-order?**\n",
                "> Column iteration causes cache misses. In C-order, consecutive column elements are far apart in memory, defeating CPU cache prefetching.\n",
                "\n",
                "**Q3: When would you use np.ascontiguousarray?**\n",
                "> After operations that break contiguity (transpose, complex slicing) when the array will be used heavily afterward, or for C extension interop.\n",
                "\n",
                "**Q4: How do you avoid memory allocation in tight loops?**\n",
                "> Use in-place operators (`*=`, `+=`), preallocate output arrays, and use `out` parameter in ufuncs."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Practice Exercises"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 1: Identify view vs copy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.arange(100).reshape(10, 10)\n",
                "\n",
                "# Which are views? Which are copies?\n",
                "a = arr[5:]\n",
                "b = arr.reshape(20, 5)\n",
                "c = arr.flatten()\n",
                "d = arr.T\n",
                "e = arr[[1, 3, 5]]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Solution\n",
                "arr = np.arange(100).reshape(10, 10)\n",
                "\n",
                "print(f\"a (slice): view = {np.shares_memory(arr, arr[5:])}\")\n",
                "print(f\"b (reshape): view = {np.shares_memory(arr, arr.reshape(20, 5))}\")\n",
                "print(f\"c (flatten): view = {np.shares_memory(arr, arr.flatten())}\")\n",
                "print(f\"d (T): view = {np.shares_memory(arr, arr.T)}\")\n",
                "print(f\"e (fancy): view = {np.shares_memory(arr, arr[[1,3,5]])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 2: Optimize matrix operation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optimize this operation for C-order arrays\n",
                "def slow_column_mean(arr):\n",
                "    result = np.zeros(arr.shape[1])\n",
                "    for j in range(arr.shape[1]):\n",
                "        result[j] = arr[:, j].mean()\n",
                "    return result\n",
                "\n",
                "arr = np.random.rand(1000, 100)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Solution: Use vectorized operation\n",
                "def fast_column_mean(arr):\n",
                "    return arr.mean(axis=0)\n",
                "\n",
                "arr = np.random.rand(1000, 100)\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    slow_column_mean(arr)\n",
                "slow_time = time.perf_counter() - start\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    fast_column_mean(arr)\n",
                "fast_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Slow: {slow_time:.4f}s\")\n",
                "print(f\"Fast: {fast_time:.4f}s\")\n",
                "print(f\"Speedup: {slow_time/fast_time:.0f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Next Notebook\n",
                "**02_vectorization_best_practices.ipynb** - Advanced vectorization patterns for maximum performance."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}