{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vectorization Best Practices\n",
                "\n",
                "**Module 07 | Notebook 02**\n",
                "\n",
                "---\n",
                "\n",
                "## Objective\n",
                "By the end of this notebook, you will master:\n",
                "- Advanced vectorization patterns\n",
                "- Common pitfalls and how to avoid them\n",
                "- When NOT to vectorize\n",
                "- Combining operations efficiently\n",
                "- Real-world optimization examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import time\n",
                "np.set_printoptions(precision=3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Avoid Temporary Arrays"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Each operation creates temporary array\n",
                "a = np.random.rand(10000000)\n",
                "b = np.random.rand(10000000)\n",
                "c = np.random.rand(10000000)\n",
                "\n",
                "# Bad: 3 temporary arrays created\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    result = a + b + c + 1  # temp1=a+b, temp2=temp1+c, temp3=temp2+1\n",
                "bad_time = time.perf_counter() - start\n",
                "\n",
                "# Better: use in-place\n",
                "result = np.empty_like(a)\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    np.add(a, b, out=result)\n",
                "    np.add(result, c, out=result)\n",
                "    np.add(result, 1, out=result)\n",
                "good_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"With temporaries: {bad_time:.3f}s\")\n",
                "print(f\"In-place: {good_time:.3f}s\")\n",
                "print(f\"Speedup: {bad_time/good_time:.2f}x\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# numexpr: automatically optimizes expressions\n",
                "try:\n",
                "    import numexpr as ne\n",
                "    \n",
                "    start = time.perf_counter()\n",
                "    for _ in range(10):\n",
                "        result = ne.evaluate('a + b + c + 1')\n",
                "    ne_time = time.perf_counter() - start\n",
                "    \n",
                "    print(f\"numexpr: {ne_time:.3f}s\")\n",
                "    print(f\"Speedup vs basic: {bad_time/ne_time:.2f}x\")\n",
                "except ImportError:\n",
                "    print(\"numexpr not installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Use Specialized Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Many operations have optimized versions\n",
                "arr = np.random.rand(10000000)\n",
                "\n",
                "# Bad: generic power\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    result = arr ** 2\n",
                "pow_time = time.perf_counter() - start\n",
                "\n",
                "# Good: specialized square\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    result = np.square(arr)\n",
                "square_time = time.perf_counter() - start\n",
                "\n",
                "# Also good: multiply\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    result = arr * arr\n",
                "mult_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"arr ** 2: {pow_time:.4f}s\")\n",
                "print(f\"np.square: {square_time:.4f}s\")\n",
                "print(f\"arr * arr: {mult_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Combined operations\n",
                "a = np.random.rand(10000, 10000)\n",
                "b = np.random.rand(10000, 10000)\n",
                "\n",
                "# Bad: sqrt(sum(...))\n",
                "start = time.perf_counter()\n",
                "result = np.sqrt(np.sum((a - b) ** 2))\n",
                "manual_time = time.perf_counter() - start\n",
                "\n",
                "# Good: np.linalg.norm\n",
                "start = time.perf_counter()\n",
                "result = np.linalg.norm(a - b)\n",
                "norm_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Manual: {manual_time:.4f}s\")\n",
                "print(f\"np.linalg.norm: {norm_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Other specialized functions:\n",
                "print(\"Specialized functions:\")\n",
                "print(\"- np.dot instead of (a * b).sum()\")\n",
                "print(\"- np.einsum for complex tensor ops\")\n",
                "print(\"- np.linalg for linear algebra\")\n",
                "print(\"- np.fft for Fourier transforms\")\n",
                "print(\"- scipy.special for special functions\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Boolean Operations Efficiently"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.random.rand(10000000)\n",
                "\n",
                "# Count elements > 0.5\n",
                "\n",
                "# Bad: create boolean array first\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    count = (arr > 0.5).sum()\n",
                "bool_time = time.perf_counter() - start\n",
                "\n",
                "# Better: np.count_nonzero\n",
                "start = time.perf_counter()\n",
                "for _ in range(10):\n",
                "    count = np.count_nonzero(arr > 0.5)\n",
                "count_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"sum of bool: {bool_time:.4f}s\")\n",
                "print(f\"count_nonzero: {count_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check any/all efficiently\n",
                "arr = np.random.rand(10000000)\n",
                "\n",
                "# Check if any > 0.5 (short-circuits!)\n",
                "start = time.perf_counter()\n",
                "for _ in range(1000):\n",
                "    has_big = np.any(arr > 0.5)\n",
                "any_time = time.perf_counter() - start\n",
                "\n",
                "# Creating boolean array first\n",
                "start = time.perf_counter()\n",
                "for _ in range(1000):\n",
                "    has_big = (arr > 0.5).any()\n",
                "create_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"np.any(condition): {any_time:.4f}s\")\n",
                "print(f\"(condition).any(): {create_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Reduce Memory Footprint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use appropriate dtype\n",
                "n = 10000000\n",
                "\n",
                "# Default float64\n",
                "arr64 = np.random.rand(n)\n",
                "print(f\"float64: {arr64.nbytes / 1e6:.1f} MB\")\n",
                "\n",
                "# float32 often sufficient\n",
                "arr32 = arr64.astype(np.float32)\n",
                "print(f\"float32: {arr32.nbytes / 1e6:.1f} MB\")\n",
                "\n",
                "# float16 for storage/transfer\n",
                "arr16 = arr64.astype(np.float16)\n",
                "print(f\"float16: {arr16.nbytes / 1e6:.1f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Performance impact\n",
                "n = 10000000\n",
                "arr64 = np.random.rand(n)\n",
                "arr32 = arr64.astype(np.float32)\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    _ = arr64.sum()\n",
                "time64 = time.perf_counter() - start\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    _ = arr32.sum()\n",
                "time32 = time.perf_counter() - start\n",
                "\n",
                "print(f\"float64 sum: {time64:.4f}s\")\n",
                "print(f\"float32 sum: {time32:.4f}s\")\n",
                "print(f\"Speedup: {time64/time32:.2f}x\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Integer types\n",
                "# Choose smallest type that fits your data\n",
                "print(\"Integer type ranges:\")\n",
                "for dtype in [np.int8, np.int16, np.int32, np.int64]:\n",
                "    info = np.iinfo(dtype)\n",
                "    print(f\"{dtype.__name__}: {info.min} to {info.max}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Chunked Processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For very large data, process in chunks\n",
                "def process_chunked(data, chunk_size, func):\n",
                "    \"\"\"Apply func to data in chunks.\"\"\"\n",
                "    results = []\n",
                "    for i in range(0, len(data), chunk_size):\n",
                "        chunk = data[i:i+chunk_size]\n",
                "        results.append(func(chunk))\n",
                "    return np.concatenate(results)\n",
                "\n",
                "# Example: normalize very large array\n",
                "large = np.random.rand(50000000)\n",
                "\n",
                "# Full normalization (might cause memory issues)\n",
                "start = time.perf_counter()\n",
                "normalized = (large - large.mean()) / large.std()\n",
                "full_time = time.perf_counter() - start\n",
                "\n",
                "# Chunked (for illustration - real impl would need global stats)\n",
                "del normalized\n",
                "print(f\"Full processing: {full_time:.3f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Avoiding Common Pitfalls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pitfall 1: Appending in loop\n",
                "# BAD: creates new array each time\n",
                "def bad_append():\n",
                "    result = np.array([])\n",
                "    for i in range(1000):\n",
                "        result = np.append(result, i)\n",
                "    return result\n",
                "\n",
                "# GOOD: preallocate\n",
                "def good_preallocate():\n",
                "    result = np.empty(1000)\n",
                "    for i in range(1000):\n",
                "        result[i] = i\n",
                "    return result\n",
                "\n",
                "# BEST: list then convert\n",
                "def best_list():\n",
                "    result = []\n",
                "    for i in range(1000):\n",
                "        result.append(i)\n",
                "    return np.array(result)\n",
                "\n",
                "print(f\"Bad append: \", end=\"\")\n",
                "start = time.perf_counter()\n",
                "bad_append()\n",
                "print(f\"{(time.perf_counter()-start)*1000:.2f}ms\")\n",
                "\n",
                "print(f\"Preallocate: \", end=\"\")\n",
                "start = time.perf_counter()\n",
                "good_preallocate()\n",
                "print(f\"{(time.perf_counter()-start)*1000:.2f}ms\")\n",
                "\n",
                "print(f\"List convert: \", end=\"\")\n",
                "start = time.perf_counter()\n",
                "best_list()\n",
                "print(f\"{(time.perf_counter()-start)*1000:.2f}ms\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pitfall 2: Copying when unnecessary\n",
                "arr = np.random.rand(1000000)\n",
                "\n",
                "# BAD: explicit copy\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    subset = arr[100:900000].copy()  # Unnecessary copy\n",
                "    _ = subset.sum()\n",
                "copy_time = time.perf_counter() - start\n",
                "\n",
                "# GOOD: use view\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    subset = arr[100:900000]  # View\n",
                "    _ = subset.sum()\n",
                "view_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"With copy: {copy_time:.4f}s\")\n",
                "print(f\"With view: {view_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pitfall 3: Wrong axis\n",
                "arr = np.random.rand(1000, 100)\n",
                "\n",
                "# Operations along different axes have different costs\n",
                "start = time.perf_counter()\n",
                "for _ in range(1000):\n",
                "    _ = arr.sum(axis=0)  # Sum columns (100 results)\n",
                "axis0_time = time.perf_counter() - start\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(1000):\n",
                "    _ = arr.sum(axis=1)  # Sum rows (1000 results)\n",
                "axis1_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Sum axis=0: {axis0_time:.4f}s\")\n",
                "print(f\"Sum axis=1: {axis1_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. When NOT to Vectorize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Case 1: Very small arrays - overhead dominates\n",
                "small = np.array([1, 2, 3])\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(100000):\n",
                "    _ = np.sum(small)\n",
                "numpy_time = time.perf_counter() - start\n",
                "\n",
                "start = time.perf_counter()\n",
                "for _ in range(100000):\n",
                "    _ = sum(small)\n",
                "python_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"np.sum on [1,2,3]: {numpy_time:.4f}s\")\n",
                "print(f\"Python sum: {python_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Case 2: Early termination needed\n",
                "# Finding first occurrence is better with loop\n",
                "\n",
                "arr = np.random.rand(10000000)\n",
                "arr[100] = 999  # Target near beginning\n",
                "\n",
                "# Vectorized: scans entire array\n",
                "start = time.perf_counter()\n",
                "for _ in range(100):\n",
                "    idx = np.argmax(arr > 998)\n",
                "vec_time = time.perf_counter() - start\n",
                "\n",
                "print(f\"Vectorized: {vec_time:.5f}s\")\n",
                "print(\"Note: Loop could stop at element 100!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Case 3: Memory-bound operations on huge arrays\n",
                "# Vectorization creates temporaries that don't fit in cache\n",
                "# Consider numba/cython for truly memory-bound cases"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Key Points Summary\n",
                "\n",
                "**Optimize by:**\n",
                "- Reducing temporary arrays (`out=`, in-place ops)\n",
                "- Using specialized functions (np.dot, np.linalg)\n",
                "- Choosing appropriate dtypes\n",
                "- Processing in chunks for huge data\n",
                "\n",
                "**Avoid:**\n",
                "- Appending in loops (preallocate!)\n",
                "- Unnecessary copies\n",
                "- Ignoring memory layout\n",
                "\n",
                "**Don't vectorize when:**\n",
                "- Arrays are tiny (overhead)\n",
                "- Early termination helps\n",
                "- Algorithm is inherently sequential"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Interview Tips\n",
                "\n",
                "**Q1: How do you reduce memory in NumPy computations?**\n",
                "> Use in-place operations, `out` parameter, smaller dtypes, and process in chunks. Use `del` to free intermediate results.\n",
                "\n",
                "**Q2: Why is np.append in a loop bad?**\n",
                "> It creates a new array each iteration, copying all previous data. O(n^2) complexity. Use list.append then np.array, or preallocate.\n",
                "\n",
                "**Q3: When might a Python loop outperform NumPy?**\n",
                "> - Tiny arrays (NumPy overhead dominates)\n",
                "> - Early termination possible\n",
                "> - Complex conditional logic per element\n",
                "\n",
                "**Q4: How do you handle arrays too large for memory?**\n",
                "> Use memory-mapped files (np.memmap), process in chunks, use libraries like Dask, or reduce precision (float32)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Practice Exercises"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 1: Optimize this computation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optimize: compute ((a + b) * c) ** 2\n",
                "a = np.random.rand(1000000)\n",
                "b = np.random.rand(1000000)\n",
                "c = np.random.rand(1000000)\n",
                "\n",
                "# Slow version (3 temporaries)\n",
                "result = ((a + b) * c) ** 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Solution\n",
                "a = np.random.rand(1000000)\n",
                "b = np.random.rand(1000000)\n",
                "c = np.random.rand(1000000)\n",
                "\n",
                "# Optimized with out parameter\n",
                "result = np.empty_like(a)\n",
                "np.add(a, b, out=result)\n",
                "np.multiply(result, c, out=result)\n",
                "np.square(result, out=result)\n",
                "\n",
                "# Verify\n",
                "expected = ((a + b) * c) ** 2\n",
                "print(f\"Match: {np.allclose(result, expected)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 2: Fix the growing array problem"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fix this code that builds array in loop\n",
                "def slow_build(n):\n",
                "    result = np.array([])\n",
                "    for i in range(n):\n",
                "        result = np.append(result, i ** 2)\n",
                "    return result\n",
                "\n",
                "# Test\n",
                "start = time.perf_counter()\n",
                "slow_build(5000)\n",
                "print(f\"Slow: {(time.perf_counter()-start)*1000:.1f}ms\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Solution 1: Preallocate\n",
                "def fast_preallocate(n):\n",
                "    result = np.empty(n)\n",
                "    for i in range(n):\n",
                "        result[i] = i ** 2\n",
                "    return result\n",
                "\n",
                "# Solution 2: Vectorize entirely\n",
                "def fastest_vectorized(n):\n",
                "    return np.arange(n) ** 2\n",
                "\n",
                "start = time.perf_counter()\n",
                "fast_preallocate(5000)\n",
                "print(f\"Preallocate: {(time.perf_counter()-start)*1000:.1f}ms\")\n",
                "\n",
                "start = time.perf_counter()\n",
                "fastest_vectorized(5000)\n",
                "print(f\"Vectorized: {(time.perf_counter()-start)*1000:.3f}ms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Next Notebook\n",
                "**03_profiling_and_benchmarking.ipynb** - Measure and identify performance bottlenecks."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}